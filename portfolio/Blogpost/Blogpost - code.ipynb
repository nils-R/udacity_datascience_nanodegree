{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:53:27.448141Z",
     "start_time": "2019-03-19T10:53:21.160770Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import variation \n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.rc('figure', figsize=(12.0, 8.0))\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore a dataset with food consumption statistics in the EU to answer the following questions:\n",
    "\n",
    "1. Have there been any changes in Sweden consumption patterns between 1997-98 and 2010-2011?\n",
    "2. What food categories are positively and negatively correlated with each other?\n",
    "3. What countries have the greatest similarities in food patterns and what food items are representative of each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection and understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset in question can be downloaded from the [efsa website](https://data.europa.eu/euodp/data/dataset/the-efsa-comprehensive-european-food-consumption-database/resource/0f73e423-b95a-408b-8e5b-a15de4fc97cf). It can also be read in directly from a url (though that increases load time). The data is available at 4 different levels of detail, with increasing granularity of each food item. For this analysis, we will only work with food items at the L1 (e.g. \"Grains and grain-based products\") and L2 (e.g. \"Pasta\") classification levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:55:19.529932Z",
     "start_time": "2019-03-19T10:53:27.509135Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Survey</th>\n",
       "      <th>Pop Class</th>\n",
       "      <th>Foodex L1</th>\n",
       "      <th>Foodex L2</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Nr Subjects</th>\n",
       "      <th>Nr Consumers</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "      <th>P5</th>\n",
       "      <th>P10</th>\n",
       "      <th>Median</th>\n",
       "      <th>P95</th>\n",
       "      <th>P97.5</th>\n",
       "      <th>P99</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austrian Study on Nutritional Status 2010-12 -...</td>\n",
       "      <td>Adults</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>A.01.000001</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austrian Study on Nutritional Status 2010-12 -...</td>\n",
       "      <td>Adults</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>Grains for human consumption</td>\n",
       "      <td>A.01.000013</td>\n",
       "      <td>308</td>\n",
       "      <td>85</td>\n",
       "      <td>15.684903</td>\n",
       "      <td>28.684094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austrian Study on Nutritional Status 2010-12 -...</td>\n",
       "      <td>Adults</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>Grain milling products</td>\n",
       "      <td>A.01.000043</td>\n",
       "      <td>308</td>\n",
       "      <td>13</td>\n",
       "      <td>2.011364</td>\n",
       "      <td>11.791651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austrian Study on Nutritional Status 2010-12 -...</td>\n",
       "      <td>Adults</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>Bread and rolls</td>\n",
       "      <td>A.01.000098</td>\n",
       "      <td>308</td>\n",
       "      <td>294</td>\n",
       "      <td>122.255519</td>\n",
       "      <td>66.426221</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.3</td>\n",
       "      <td>250.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Austrian Study on Nutritional Status 2010-12 -...</td>\n",
       "      <td>Adults</td>\n",
       "      <td>Grains and grain-based products</td>\n",
       "      <td>Pasta (Raw)</td>\n",
       "      <td>A.01.000168</td>\n",
       "      <td>308</td>\n",
       "      <td>89</td>\n",
       "      <td>24.813312</td>\n",
       "      <td>45.993167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country                                             Survey Pop Class  \\\n",
       "0  Austria  Austrian Study on Nutritional Status 2010-12 -...    Adults   \n",
       "1  Austria  Austrian Study on Nutritional Status 2010-12 -...    Adults   \n",
       "2  Austria  Austrian Study on Nutritional Status 2010-12 -...    Adults   \n",
       "3  Austria  Austrian Study on Nutritional Status 2010-12 -...    Adults   \n",
       "4  Austria  Austrian Study on Nutritional Status 2010-12 -...    Adults   \n",
       "\n",
       "                         Foodex L1                        Foodex L2  \\\n",
       "0  Grains and grain-based products  Grains and grain-based products   \n",
       "1  Grains and grain-based products     Grains for human consumption   \n",
       "2  Grains and grain-based products           Grain milling products   \n",
       "3  Grains and grain-based products                  Bread and rolls   \n",
       "4  Grains and grain-based products                      Pasta (Raw)   \n",
       "\n",
       "       Metrics  Nr Subjects  Nr Consumers        Mean        STD    P5   P10  \\\n",
       "0  A.01.000001          308             0    0.000000   0.000000   0.0   0.0   \n",
       "1  A.01.000013          308            85   15.684903  28.684094   0.0   0.0   \n",
       "2  A.01.000043          308            13    2.011364  11.791651   0.0   0.0   \n",
       "3  A.01.000098          308           294  122.255519  66.426221  10.0  50.0   \n",
       "4  A.01.000168          308            89   24.813312  45.993167   0.0   0.0   \n",
       "\n",
       "   Median    P95  P97.5    P99 Comment  \n",
       "0     0.0    0.0    0.0    0.0          \n",
       "1     0.0   61.0  112.0  112.0          \n",
       "2     0.0    0.0   33.0   65.5          \n",
       "3   120.0  236.3  250.0  275.0          \n",
       "4     0.0  125.0  155.0  170.0          "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheetname = 'L2_All_subjects_g_day'\n",
    "filename = 'chronicgdaytotpop.xlsx'\n",
    "    \n",
    "try:\n",
    "    df = pd.read_excel(filename, sheet_name=sheetname, skiprows=range(2))\n",
    "except:\n",
    "    df = pd.read_excel(f'http://www.efsa.europa.eu/sites/default/files/{filename}', sheet_name=sheetname, skiprows=range(2))\n",
    "df = df.rename(columns={'Nr Subjetcs':'Nr Subjects'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:55:20.099875Z",
     "start_time": "2019-03-19T10:55:19.624922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shorten category names and save a mapping between level 1 and level 2 food items\n",
    "df[['Foodex L1', 'Foodex L2']] = df[['Foodex L1', 'Foodex L2']].apply(lambda x: x.str.split('(').str[0].str.strip())\n",
    "food_key = {row[1]: row[0] for i, row in df[['Foodex L1', 'Foodex L2']].drop_duplicates().iterrows()}\n",
    "# Restrict analysis to adults only\n",
    "df = df[df['Pop Class']=='Adults']\n",
    "df = df[df['Foodex L1']!='Food for infants and small children']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate if there are any missing values in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T11:02:20.244254Z",
     "start_time": "2019-03-19T11:02:20.190254Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country         False\n",
       "Survey          False\n",
       "Pop Class       False\n",
       "Foodex L1       False\n",
       "Foodex L2       False\n",
       "Metrics         False\n",
       "Nr Subjects     False\n",
       "Nr Consumers    False\n",
       "Mean            False\n",
       "STD             False\n",
       "P5              False\n",
       "P10             False\n",
       "Median          False\n",
       "P95             False\n",
       "P97.5           False\n",
       "P99             False\n",
       "Comment         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure each food item is measured in the same metric across surveys - each item should have only one unique code each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:55:20.242861Z",
     "start_time": "2019-03-19T10:55:20.198865Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nunique  Foodex L2     1\n",
       "         Metrics       1\n",
       "count    Metrics      23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index=[f'Foodex L2'], values='Metrics', aggfunc=['nunique', 'count']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming from Sweden, I'm especially interested in the consumption patterns here and how they have evolved over time. Looking at the data, we can see that one survey was performed twice, about 15 years apart. Let's see if there were any significant changes between the two: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T19:27:04.550729Z",
     "start_time": "2019-03-17T19:27:01.499729Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def group_by_year(df, food_lvl, is_rank=True):\n",
    "    \"\"\"\n",
    "    Group data by year and mean consumption of each food category\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe\n",
    "        food_lvl: Food level to group by\n",
    "        is_rank: Option to summarize by rank instead of total consumption\n",
    "    Returns:\n",
    "        (DataFrame) df: Grouped dataframe\n",
    "        (array) labels: Array of strings that specify food item\n",
    "        (array) c: Array of floats that specify the absolute difference between the last period and the pervious one\n",
    "    \"\"\"\n",
    "    df = df.pivot_table(index=food_lvl, columns='Survey', values='Mean')\n",
    "    if is_rank:\n",
    "        df = df.rank(ascending=False).astype(int)\n",
    "        val = 'rank'\n",
    "    else:\n",
    "        val = 'g/day'\n",
    "    df.columns = ['1997-98', '2010-11']\n",
    "    df = df.sort_values(by='2010-11')\n",
    "    c = df.diff(axis=1).abs().iloc[:,1].values # Use difference between surveys for color highlighting\n",
    "    labels = df.index.values\n",
    "    # Convert to long format for easier plotting\n",
    "    df = pd.melt(df.reset_index(), id_vars=food_lvl, var_name='period', value_name=val)\n",
    "    return df, labels, c\n",
    "\n",
    "def annotate_pointplot(ax, labels, topk=100):\n",
    "    \"\"\"\n",
    "    Annotate pointplot chart with labels\n",
    "\n",
    "    Args:\n",
    "        ax: Axis to use for plotting\n",
    "        labels: List of text labels to annotate\n",
    "        topk: Option to only annotate the topk most common labels\n",
    "    \"\"\"\n",
    "    for i, co in enumerate(ax.collections):\n",
    "        for x, y in co.get_offsets():\n",
    "            if x == 1 and i >= len(ax.collections)-topk:\n",
    "                label = labels[i]\n",
    "                ax.annotate(label, (x*1.03, y))\n",
    "\n",
    "def create_palette(c, style='copper'):\n",
    "    \"\"\"\n",
    "    Creates a sequential palette based on the min and max value in an array\n",
    "\n",
    "    Args:\n",
    "        c: Numeric array\n",
    "        style: Cmap style \n",
    "    Returns:\n",
    "        (object) palette: Sequential palette \n",
    "    \"\"\"\n",
    "    cmap = plt.get_cmap(style)\n",
    "    norm = mpl.colors.Normalize(vmin=min(c), vmax=max(c))\n",
    "    palette = cmap(norm(c))\n",
    "    return palette\n",
    "\n",
    "swe = df[df['Country']=='Sweden']\n",
    "food_lvl = 'Foodex L1'\n",
    "\n",
    "swe1, labels, c = group_by_year(swe, food_lvl, is_rank=True)\n",
    "palette = create_palette(c)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.pointplot(x=\"period\", y=\"rank\", hue=food_lvl, data=swe1, ax=ax, palette=palette)\n",
    "ax.legend('')\n",
    "\n",
    "plt.title('Swedish changes in food consumption between 1997-98 and 2010-11')\n",
    "plt.gca().invert_yaxis()\n",
    "annotate_pointplot(ax, labels)\n",
    "\n",
    "plt.savefig('images/swe_lvl1.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T19:26:44.136329Z",
     "start_time": "2019-03-17T19:26:35.786729Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories = ['Non-alcoholic beverages', 'Alcoholic beverages',\n",
    "              'Fruit and vegetable juices', 'Drinking water',\n",
    "              'Vegetables and vegetable products', 'Meat and meat products']\n",
    "\n",
    "swe = df[df['Country']=='Sweden']\n",
    "food_lvl = 'Foodex L2'\n",
    "nrows = int(len(categories)/2)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20,16), nrows=nrows, ncols=2)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "#fig.suptitle('Swedish changes in food consumption between 1997-98 and 2010-11')\n",
    "is_rank=False\n",
    "if is_rank:\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "for ax, category in zip(axes.flatten(), categories):\n",
    "    swe1 = swe[ swe['Foodex L1']==category ]\n",
    "    swe1, labels, c = group_by_year(swe1, food_lvl, is_rank=is_rank)\n",
    "    palette = create_palette(c)\n",
    "    sns.pointplot(x=\"period\", y=\"g/day\", hue=food_lvl, data=swe1, ax=ax, palette=palette)\n",
    "    ax.legend('')\n",
    "    annotate_pointplot(ax, labels, topk=5)  \n",
    "    ax.set(title=category)\n",
    "    \n",
    "plt.savefig('images/swe_lvl2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compare the food consumption in different countries. To simplify the analysis, we'll only focus on the average consumption in each country and disregard its within-country distribution. Also, in cases where there have been several studies in the same country, we'll weigh them according to the number of respondents in each study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:18:16.358512Z",
     "start_time": "2019-03-17T18:18:16.076912Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Sum'] = df['Mean'] * df['Nr Subjects']\n",
    "dft = df.groupby(['Country', f'Foodex L1']).sum()\n",
    "dft['Mean'] = dft['Sum'] / dft['Nr Subjects']\n",
    "dft = dft['Mean'].reset_index().pivot_table(index='Country', columns='Foodex L1', values='Mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compare variation in consumption across a number of different food items, we'll scale them so that each item has a mean of zero and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:18:21.622312Z",
     "start_time": "2019-03-17T18:18:21.594712Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index = dft.index\n",
    "cols = dft.columns.str.split('(').str[0]\n",
    "scaler = StandardScaler()\n",
    "df_s = scaler.fit_transform(dft)\n",
    "df_s = pd.DataFrame(df_s, index=index, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T17:31:36.204702Z",
     "start_time": "2019-03-17T17:31:36.189102Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_rare_items(df, n=10):\n",
    "    \"\"\"\n",
    "    Remove features that have less than a minimum number of non-zero/null records\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe\n",
    "        n: Threshold\n",
    "    Returns:\n",
    "        (dataframe) df: Dataframe cleaned of columns with less than n non-zero values\n",
    "    \"\"\"\n",
    "    mask = (df.astype(bool).sum()>n)\n",
    "    df = df[mask[mask==True].index]\n",
    "    #keepcols = df.apply(variation).sort_values(ascending=False)[:30].index\n",
    "    return df#[keepcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T19:25:51.873729Z",
     "start_time": "2019-03-17T19:25:42.851729Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_correlations(df):\n",
    "    \"\"\"\n",
    "    Create a diagonal correlation matrix\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe\n",
    "    \"\"\"\n",
    "    mtrx = df.corr(method='pearson')\n",
    "    mask = np.zeros_like(mtrx, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "       \n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.heatmap(mtrx, mask=mask, annot=True, fmt='0.00%', vmax=1, cmap=cmap, square=False, linewidths=1)\n",
    "\n",
    "plot_correlations(dft)\n",
    "plt.savefig('images/correlation.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll apply a technique called Principal Component Analysis (PCA) which lets us reduce the amount of variables. While this will make us lose some of the information in the data, it reduces complexity and makes it much easier to interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T17:37:14.208503Z",
     "start_time": "2019-03-17T17:37:12.616103Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_pca(df, n):\n",
    "    \"\"\"\n",
    "    Fit pca on a dataframe and return the resulting matrix and the pca estimator\n",
    "    Args:\n",
    "        df: Dataframe\n",
    "        n: number of components to reduce to\n",
    "    Returns:\n",
    "        (matrix) X: Transformed matrix\n",
    "        (object) pca: PCA object\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n)\n",
    "    X = pca.fit_transform(df_s)\n",
    "    return X, pca\n",
    "\n",
    "def fit_kmeans(X, n):\n",
    "    \"\"\"\n",
    "    Fit kmeans on a dataframe and return the predicted clusters and the kmeans estimator\n",
    "    Args:\n",
    "        X: Matrix\n",
    "        n: number of clusters to fit\n",
    "    Returns:\n",
    "        (array) clusts: Predicted cluster label of each input row \n",
    "        (object) kmeans: KMeans object\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n)\n",
    "    clusts = kmeans.fit_predict(X)\n",
    "    return clusts, kmeans\n",
    "\n",
    "def calculate_kmeans_scores(X):\n",
    "    \"\"\"\n",
    "    Over a number of different cluster counts, run k-means clustering on the data and compute the average within-cluster distances\n",
    "    Args:\n",
    "        X: Matrix\n",
    "    Returns:\n",
    "        (array) kscores: Array of average within-cluster distances for a choice of 1-9 clusters\n",
    "    \"\"\"\n",
    "    kscores = {n: int(KMeans(n).fit(X).score(X)) for n in range(1,10)}\n",
    "    return kscores\n",
    "\n",
    "def plot_kmeans_scores(kscores):\n",
    "    \"\"\"\n",
    "    Plot within-cluster distances for different number of clusters\n",
    "    Args:\n",
    "        kscores: Array of average within-cluster distances\n",
    "    \"\"\"\n",
    "    x = kscores.keys()\n",
    "    y = [np.abs(val) for val in kscores.values()]\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x, y, linestyle='--', marker='o', color='b')\n",
    "    \n",
    "X, pca = fit_pca(df_s, 2)\n",
    "kscores = calculate_kmeans_scores(X)\n",
    "plot_kmeans_scores(kscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the graph above, the additional benefit of more than 4 clusters in marginal. Therefore, let's fit 4 different clusters of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:40:30.314317Z",
     "start_time": "2019-03-17T18:40:30.249117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reduce the number of dimensions and fit cluster centers\n",
    "X, pca = fit_pca(df, 2)        \n",
    "clusts, kmeans = fit_kmeans(X, n=4)\n",
    "print(f'Explained variability: {pca.explained_variance_ratio_.sum():.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll plot where each country fits in terms of the derived principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T19:38:24.258932Z",
     "start_time": "2019-03-17T19:38:22.663332Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def annotate_scatter_plot(X, labels, ax):\n",
    "    \"\"\"\n",
    "    Annotate scatter plot with labels\n",
    "\n",
    "    Args:\n",
    "        X: Matrix with coordinates of each point to annotate\n",
    "        labels: List of text labels to annotate\n",
    "        ax: Axis to use for plotting\n",
    "    \"\"\"\n",
    "    for i, text in enumerate(text):\n",
    "        x = X[i,0]\n",
    "        y = X[i,1]\n",
    "        #if text in subset:\n",
    "        ax.text(x, y, labels, fontsize=9, alpha=.7)    \n",
    "\n",
    "# Plot countries along pca-axises\n",
    "fig1 = plt.figure();\n",
    "ax1 = plt.gca()\n",
    "clusters = kmeans.predict(X)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], legend=False, ax=ax1, hue=clusters);\n",
    "countries = df_s.index\n",
    "annotate_scatter_plot(X, countries, ax1);\n",
    "# Plot cluster centers\n",
    "ax1.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker='x', color='blue');\n",
    "plt.savefig('images/scores2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - we seem to have a latin, an eastern european and a germanic cluster. We also has a cluster that is less obvious, consisting of Ireland, Czech and Denmark. Let's compare these clusters to how the food items contribute to each principal component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T19:37:28.111932Z",
     "start_time": "2019-03-17T19:37:26.744132Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot where each food item lies along pca axises\n",
    "fig2 = plt.figure();\n",
    "ax2 = plt.gca()\n",
    "data=pd.DataFrame(pca.components_.T[:,:2])\n",
    "data['label'] = [food_key[x] for x in df_s.columns]\n",
    "sns.scatterplot(x=0, y=1, data=data, hue='label', legend=False, ax=ax2)\n",
    "food_items = df_s.columns\n",
    "annotate_scatter_plot(data.values, food_items, ax2)\n",
    "\n",
    "#plt.savefig('images/loadings2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, the latin countries have a high consumption of fruit and seafood while the eastern european cluster has a high degree of fats and animal products. This also explains the not immediately obvious cluster of Ireland, Czech and Denmark - they all have high volumes of carbohydrates such as grains, sugar, beer and potatoes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T18:35:49.302916Z",
     "start_time": "2019-03-17T18:35:46.284116Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot3D(X, labels, ax):\n",
    "    \"\"\"\n",
    "    Plot 3D scatterplot and annotate points with labels\n",
    "\n",
    "    Args:\n",
    "        X: Matrix with coordinates of each point to annotate\n",
    "        labels: List of text labels to annotate\n",
    "        ax: Axis to use for plotting\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.title(f'Explained variability: {pca.explained_variance_ratio_.sum():.1%}')    \n",
    "    ax.set_xlabel(f'Component 0')\n",
    "    ax.set_ylabel(f'Component 1')\n",
    "    ax.set_zlabel(f'Component 2')\n",
    "    \n",
    "    for i, c in enumerate(X):\n",
    "        x = X[i,0]\n",
    "        y = X[i,1]\n",
    "        z = X[i,2]\n",
    "        mark = 'o' #if representation[i]>0 else '^'\n",
    "        ax.scatter(x, y, z, marker=mark, s=40)\n",
    "        ax.text(x, y, z, labels[i], size=8, alpha=0.7)\n",
    "\n",
    "X, pca = fit_pca(df, 3)        \n",
    "clusts, kmeans = fit_kmeans(X, n=3)\n",
    "\n",
    "fig = plt.figure(figsize=(12,16))\n",
    "ax = fig.add_subplot(211, projection='3d')\n",
    "countries = df_s.index\n",
    "plot3D(X, countries, ax)\n",
    "ax = fig.add_subplot(212, projection='3d')\n",
    "food_items = df_s.columns\n",
    "plot3D(pca.components_.T[:,:3], food_items, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-17T17:31:36.622902Z",
     "start_time": "2019-03-17T17:29:02.962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset = pd.read_excel('food_subset.xlsx')\n",
    "subset = subset.loc[subset['Include']=='x', 'Foodex L2'].values\n",
    "dft[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
